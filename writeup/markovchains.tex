\documentclass{amsart}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage{csquotes}
\usepackage{todonotes}
\usepackage{verbatim}
\usepackage{amssymb}

\usepackage{tikz}
\usepackage{tikz,fullpage}
\usetikzlibrary{arrows,%
                petri,%
                topaths}%
\usepackage{tkz-berge}
\usepackage[position=top]{subfig}




\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}


\theoremstyle{definition}
\newtheorem{definition}[thm]{Definition}
\newtheorem{example}[thm]{Example}
\newtheorem{theorem}{Theorem}

\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}

\newtheorem{remark}[thm]{Remark}

\newtheorem{corollary}{Corollary}[theorem]

%%%
%%% The following, if uncommented, numbers equations within sections.
%%% 

\numberwithin{equation}{section}


\title{Regular Transition Matrices}
\author{Joseph Tobin}
\date{27 November 2017}

\begin{document}

\maketitle

%include abstract

%5.17 - end
%presentation the week after break
%email rough draft over beak
%lookup and use jordan canonical form without proof


\section{Introduction}



\section{Theorems}

\begin{theorem}[Theorem 5.18 pg. 298]
Let $A \in M_{n \lambda n} (C)$ be a matrix in which each entry is positive and let $\lambda$ be an eigenvalue of $A$ such that $| \lambda | = \rho(A)$.
Then $\lambda = \rho(A)$ and $\{ u \}$ is a basis for $E_{\lambda}$, where $u \in C^n$ is the column vector in which each coordinate equals $1$.

\end{theorem}

\begin{proof}
First, note that because $A$ has all postitive values and $u$ has all positive values, then $Au$ has all postive values. Therefore, because $\lambda u = Au$ has all positive values we can conclude $\lambda > 0$ and $\lambda = |\lambda| = \rho(A)$

\todo{how do we know 1 is an eigenvalue of A? we don't know that it's a transition matrix?}

Now let $v$ be an eigenvector of $A$ corresponding to $\lambda$ with coordinates $v_1, v_2, \ldots, v_n$.  
Then let $v_k = max(|v_1|, |v_2|, \ldots |v_n|)$ and $b = |v_k|$.

Then $$ |\lambda| b = |\lambda| |v_k| = |\lambda v_k| $$
But if $\lambda$ is an eigenvalue of $A$, then $Av = \lambda v$ and thus $\forall 1 \leq i \leq n \lambda v_i = \sum_{j = 1}^n A_{ij}v_j$.
Thus

$$ |\lambda v_k| = | \sum_{j = 1}^n A_{kj}v_j | $$

By the triangle inequality and then multiplication rules,

$$ | \sum_{j = 1}^n A_{kj}v_j | \leq \sum_{j=1}^n |A_{kj}v_j| = \sum_{j=1}^n |A_{kj}| |v_j| $$

Since we know $b = |v_k| \geq v_i \forall 1 \leq i \leq n$ and similarly $\rho(A) \geq  \rho_i(A) \forall 1 \leq i \leq n $, we know 

$$ \sum_{j=1}^n |A_{kj}| |v_j|  \leq \sum_{j=1}^n |A_{kj}| b = b \sum_{j=1}^n |A_{kj}| =  b\rho_k(A) = \rho_k(A)b \leq \rho(A)b $$


But since we know $|\lambda| = \rho(A)$, we know the three inequalities above are actually equalities.

\begin{enumerate}

	\item $| \sum_{j = 1}^n A_{kj}v_j | = \sum_{j=1}^n |A_{kj}v_j|$

	\item $\sum_{j=1}^n |A_{kj}| |v_j|  = \sum_{j=1}^n |A_{kj}| b$

	\item $\rho_k(A)b = \rho(A)b$

\end{enumerate}


But now we can use this to show that $\{ u \}$ is a basis for $E_{\lambda}$



\end{proof}

\begin{corollary}[Corollary 1 pg. 299]

	Let $A \in M_{n \times n}(C)$ be a matrix in which each entry is positiive and let $\lambda$ be an eigenvalue of $A$ such that $|\lambda| = \nu(A)$.
	Then  $\lambda = \nu(A)$ and $E_{\lambda}$ has dimension 1.

\end{corollary}

\begin{proof}

	Consider $A^T$.  
	We know by execercise 14 of 5.1 in \cite{friedberg2003linear} that $A$ and $A^T$ have the same eigenvalues.
	Let $E_{\lambda}, E_{\lambda}\textprime$ be the eigenspaces of $\lambda$ corresponding to $A, A^T$ respectively.
	Additionally, if $|\lambda| = \nu(A)$, then the row \todo{define nu, rho, clarify} corresponding to $\nu(A)$ is now a column in $A^T$ such that $|\lambda| = \rho(A^T)$.
	Thus $A^T$ is a matrix in which each entry is positive with an eigenvalue $\lambda = \rho(A^T)$.
	Thus by Theorem 5.18 \cite{friedberg2003linear}, the basis of $E_{\lambda}\textprime = \{ u \}$, where $u \in C^n$ is the column vector in which each coordinate contains $1$ and $\lambda = \rho(A^T)$.
	Thus $dim(E_{\lambda}\textprime) = 1$.
	But by exercise $13$ of $5.2$ of \cite{friedberg2003linear}, we know $dim(E_{\lambda}) = dim(E_{\lambda}\textprime) = 1$ and $\nu(A) = \rho(A^T) = \lambda$.
	Thus, we have shown $\lambda = \nu(A)$ and $dim(E_{\lambda}) = 1$.

\end{proof}



\begin{corollary}[Corollary 2 pg. 299]

	Let $A \in M_{n \times n}(C)$ be a transition matrix in which each entry is positiive and let $\lambda$ be an eigenvalue of $A$ such that $\lambda \neq 1$.
	Then  $|\lambda| < 1$ and the eigenspace corresonding to the eigenvalue $1$ has dimension $1$.

\end{corollary}

\begin{proof}
	We know by corollary 3 of Theorem 5.16 \cite{friedberg2003linear} that if $\lambda$ is an eigenvalue of a transition matrix, then $|\lambda| \leq 1$.
	Thus if $|\lambda| \neq 1$, then $|\lambda| < 1$.

	If $A$ is a transition matrix, then by Theorem 5.17 \cite{friedberg2003linear} we know that $1$ is an eigenvalue. 

	We also know that if $A$ is a transition matrix, then given $u$ as a column vector in which each coordinate equals 1, then $A^Tu = u$.
	But since $u$ is the column vector equal to $1$, each $u_i$ in $u$ is equal to the sum along the columns of $A^T$.
	But because $u_i = 1 \forall i$, then $\nu_i(A) = 1 \forall i$ and thus $\nu(A) = 1$.

	Thus we have an all-positive-entry matrix with $1 = \lambda = \nu(A) $ and thus by Corollary 1 of Theorem 5.18 \todo{fancy citing}, we know $dim(E_{\lambda}) = 1$.


\end{proof}

\begin{theorem}[Theorem 5.19 pg. 298]
Let $A$ be a regular transition matrix and let $\lambda$ be an eigenvalue of $A$.  Then 

\begin{enumerate}
	\item $|\lambda| \leq 1$
	\item If $|\lambda| = 1$, then $\lambda = 1$ and $dim(E_{\lambda}) = 1$.

\end{enumerate}

\end{theorem}

\begin{proof}

We know $(1)$ was proved in Corollary 3 of Theorem 5.16 \cite{friedberg2003linear}.

Since $A$ is regular, we know by definition $\exists s > 0 \in \mathbb{Z}$ such that $A^s$ has only positive entries
Because $A$ is a transition matrix and the entries of $A^s$ are positive, we know the entries of $A^{s+1} = A^s(A)$ are positive \todo{note that we're just summing over the coluymns of A which have sum one}
Suupose $|\lambda| = 1$, then we know by by Probelem $15b$ of section $5.1$ in \cite{friedberg2003linear} that if $\lambda$ is a eigenvalue of $A$, then $\lambda^s$, $\lambda^{s+1}$ are eigenvalues of $A$, $A^{s+1}$ respectively with $ |\lambda^s |= |\lambda^{s+1} |= |\lambda| = 1$.

Because each entry of $A^s$, $A^{s+1}$ is positive, we know that for any eigenvalues $\lambda*$ of $A^s$, $A^{s+1}$ such that $\lambda* \neq 1$, then $|\lambda| < 1$.
Thus because $|\lambda^s |= |\lambda^{s+1} |= 1 $, we can conclude $\lambda^s = \lambda^{s+1} = 1$ and therefore $\lambda = 1$.

Let $E_{\lambda}$ and $E_{\lambda}\textprime$ be the eigenspaces of $A$, $A^{s+1}$ respectively corresponding to $\lambda = 1$.
Then $E_{\lambda} \subseteq E_{\lambda}\textprime$ \todo{whyy?} and because $dim(E_{\lambda}\textprime) = 1$, we know $dim(E_{\lambda}) = 1$.


\end{proof}


\begin{corollary}[Corollary Pg. 300]
Let $A$ be a regular transition matrix that is diagonalizble.
Then $\lim_{m \to \infty} A^m$ exists.

\end{corollary}

\begin{proof}

We know by Theorem 5.14 \cite{friedberg2003linear} that if $A \in M_{n \times n}(C)$ is diagonalizable and has every eigenvalue contained in $S$, where $S = \{ \lambda \in C: |\lambda| < 1$ or $|\lambda| = 1\}$, then $\lim_{m \to \infty} A^m$ exists.


Thus because $A$ is dianolizable by assumption, we just need to show for all eigenvalues $\lambda$ of $A$, $\lambda \in S$.
But we know by Theorem 5.19 $\forall$ eigenvalues $\lambda$ that $\lambda = 1$ or $|\lambda| < 1$ and thus $\lambda \in S$.
Thus we can conclude that $\lim_{m \to \infty} A^m$ exists.

\end{proof}

\begin{theorem}[Theorem 5.20]

Let $A$ be an $n \times n$ regular transition matrix. Then:

\begin{enumerate}

	\item The multiplicity of $1$ as an eigenvalue of $A$ is $1$.

	\item $\lim_{m \to \infty} A^m$ exists.

	\item $L = \lim_{m \to \infty} A^m$ is a transition matrix.

	\item $LA = AL = L$.

	\item The columns of $L$ are identical and equal to the unique probability vector $v$ that is equal to the eigenvalue $1$.

	\item For any probability vector $w$, $\lim_{m \to \infty} A^m w = v$.

\end{enumerate}

\end{theorem}

\begin{proof}

\begin{enumerate}

	\item See exercise 20 of section 7.2

	\item 	1, 5.13, 5.19

	\item 
			By theorem 5.15 \cite{friedberg2003linear}, we know $L$ is a transition matrix if $L^tu = u$, where $u$ is the column vector where every entry is equal to $1$
			Due to the equivalence, we can  know $L$ is a transition matrix is  $u^tL = u^t$.
			But 
			$$u^tL = u^t \lim_{m \to \infty} A^m = \lim_{m \to \infty} u^t A^m$$

			But $A^m$ is a transition matrix which means $\forall m u^t A^m = u^t$ and thus
			$$\lim_{m \to \infty} u^t A^m = \lim_{m \to \infty} u^t = u^t $$

			Thus $L$ is a transition matrix.


	\item 

			By Theorem 5.12 \cite{friedberg2003linear}, we know $AL = \lim_{m \to \infty} A A^m = \lim_{m \to \infty} A^{m+1} = \lim_{m \to \infty} A^mA  = LA$.

			But $\lim_{m \to \infty} A^{m+1} = \lim_{m \to \infty} A^{m} = L$.

			Thus $LA = AL = L$.


	\item 
			We know $AL = L$ by $(4)$.
			Let $L_i$ be the $ith$ column vector of $L$.
			Then because $AL = L$, we know $AL_i = L_i \forall 1 \leq i \leq n$.
			Thus $L_i$ is an eigenvector of $A$ corresponding to eigenvalue $\lambda = 1$.

			Additionally, because $L$ is a transition matrix by $(3)$, we know $L^tu = u$ and thus $\forall 1 \leq i \leq n L_i^t u = u$.
			Thus $\forall 1 \leq i \leq n L_i$ is a probability vector.

			But then using $(1)$, we know that the multiplicity of $1$ as an eigenvalue of $A$ is 1.
			Thus all the columns of $L$ have to be a scalar multiple of the same vector.
			But because every column is a probability vector, they have to be the same in order to satisify $\forall 1 \leq i \leq n L_i^t u = u$. \todo{need to prove?}

			Thus each column of $L$ is equal to the the unique probability vector $v$ corresponding to eigenvalue $1$.

	\item 
		Let $w$ be any probability vector and $y = \lim_{m \to \infty} A^m w  = Lw$.
		We want to show $y = v$.
		,
		If $y = Lw$, then by the corollary to Theorem 5.15 \cite{friedberg2003linear}, we know $y$ is a probability vector.

		Additionally,
		$$Ay = A(Lw) = (AL)w = Lw$$
		by part $(4)$.
		But $Lw = y$ and thus $Ay = y$.

		Therefore $y$ is an probability vector and eigenvector of $A$ corresponding to $\lambda = 1$
		But $v$ is the unique probability vector and eigenvector of $A$ corresponding to $\lambda = 1$ and thus $y = v$.

		Thus $\lim_{m \to \infty} A^m w = v$.


\end{enumerate}


\end{proof}

\section{Applications}

\bibliographystyle{alpha}
\bibliography{MathCitations} 


\end{document}